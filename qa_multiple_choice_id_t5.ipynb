{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37dd2e21-dc41-46f7-a294-0728ae25c80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
      "  warnings.warn(\n",
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"guid\": 0,\n",
      "  \"label\": 3,\n",
      "  \"meta\": {},\n",
      "  \"text_a\": \"Pick the option in line with common sense to answer the question.\\nQuestion: It was the only way out of town, the police parked their vehicles and drew their guns to create a what?\\nOptions:\\n\\nA. war\\n\\nB. sporting goods store\\n\\nC. military base\\n\\nD. roadblock\\n\\nE. fun\\n\\n\",\n",
      "  \"text_b\": \"\",\n",
      "  \"tgt_text\": null\n",
      "}\n",
      "\n",
      "<class 'openprompt.data_utils.utils.InputExample'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizing: 150it [00:00, 1147.18it/s]\n",
      "tokenizing: 500it [00:00, 1422.81it/s]\n",
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 1.5899412631988525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:24<?, ?it/s, loss=1.67]\n",
      "Training:   0%|          | 0/30 [01:24<?, ?it/s, loss=1.67]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.71]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.7] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 1.7012322545051575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:18<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:23<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:43<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:45<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:48<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:52<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:57<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:00<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 1.6779685020446777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.68]\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.68]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:01<?, ?it/s, loss=1.72]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.57]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 1.5705686807632446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.59]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:18<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:26<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:36<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 1.6333264708518982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:08<?, ?it/s, loss=1.68]\n",
      "Training:   0%|          | 0/30 [01:08<?, ?it/s, loss=1.68]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.8]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.68]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 1.6783061027526855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:07<?, ?it/s, loss=1.75]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.71]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.72]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.73]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.74]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.73]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.7] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.71]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.7] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:48<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:51<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:52<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:55<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.5] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 1.4973579049110413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [00:45<?, ?it/s, loss=1.67]\n",
      "Training:   0%|          | 0/30 [00:45<?, ?it/s, loss=1.67]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.78]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.68]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 1.6807405948638916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:10<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:23<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:36<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:41<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:43<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 1.6087524890899658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.66]\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.66]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:01<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.58]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 1.5773894786834717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:10<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:23<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:26<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.7] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Epoch 10: 0.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "tokenizing: 150it [00:00, 1262.92it/s]\n",
      "tokenizing: 500it [00:00, 1383.29it/s]\n",
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/30 [01:38<?, ?it/s, loss=1.7]\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 1.6454914212226868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:04<?, ?it/s, loss=1.68]\n",
      "Training:   0%|          | 0/30 [01:04<?, ?it/s, loss=1.68]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:01<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.6] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 1.5967612266540527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.59]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:07<?, ?it/s, loss=1.57]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.57]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.59]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:26<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:32<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:36<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:41<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:47<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.57]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 1.5686908960342407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:09<?, ?it/s, loss=1.66]\n",
      "Training:   0%|          | 0/30 [01:09<?, ?it/s, loss=1.66]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.89]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.67]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 1.6714516282081604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.58]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:43<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:55<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:59<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:05<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:11<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:17<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:23<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:28<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:33<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:39<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:44<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:49<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:54<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:58<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:02<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:07<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:12<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:17<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:21<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:26<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:31<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:35<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:40<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.59]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 1.5941259264945984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [02:21<?, ?it/s, loss=1.66]\n",
      "Training:   0%|          | 0/30 [02:21<?, ?it/s, loss=1.66]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.55]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 1.5457215309143066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.54]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.56]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.57]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.6]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:23<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:34<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:41<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:43<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:47<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:50<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.68]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 1.6848066449165344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [04:19<?, ?it/s, loss=1.7] \n",
      "Training:   0%|          | 0/30 [04:19<?, ?it/s, loss=1.7]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:18<?, ?it/s, loss=1.73]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.64]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 1.6356967687606812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:11<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [01:28<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:44<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:00<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:17<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:33<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:47<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:02<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:17<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:34<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:50<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:07<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:23<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:39<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:54<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [05:10<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [05:25<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [05:39<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [05:56<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [06:11<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [06:24<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [06:37<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [06:50<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [07:01<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [07:12<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [07:24<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [07:34<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 1.6163816452026367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [04:22<?, ?it/s, loss=1.65]\n",
      "Training:   0%|          | 0/30 [04:22<?, ?it/s, loss=1.65]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.59]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 1.5904827117919922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.56]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:45<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:52<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:59<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:07<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:14<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:22<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:29<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:37<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:44<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:51<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:58<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:06<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:14<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:21<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:29<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:36<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:41<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:47<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:52<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:56<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:00<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:05<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:09<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:13<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:18<?, ?it/s, loss=1.65]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Epoch 10: 0.1960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "tokenizing: 150it [00:00, 1291.60it/s]\n",
      "tokenizing: 500it [00:00, 1325.34it/s]\n",
      "/lustre/work/client/users/minhos/.conda/envs/prompt_learning_env/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/30 [04:21<?, ?it/s, loss=1.65]\n",
      "Training:   0%|          | 0/30 [00:07<?, ?it/s, loss=1.63]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average loss: 1.6316540837287903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:21<?, ?it/s, loss=1.7] \n",
      "Training:   0%|          | 0/30 [01:21<?, ?it/s, loss=1.7]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.78]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:05<?, ?it/s, loss=1.59]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, average loss: 1.5870569944381714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:16<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:18<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:23<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:28<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:30<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:35<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:37<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:41<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:51<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:53<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:55<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:01<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:03<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:05<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:08<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:09<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.65]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, average loss: 1.652706503868103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [01:05<?, ?it/s, loss=1.68]\n",
      "Training:   0%|          | 0/30 [01:05<?, ?it/s, loss=1.68]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:02<?, ?it/s, loss=1.73]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.7] \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, average loss: 1.6951058506965637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.7]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:08<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:11<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:13<?, ?it/s, loss=1.71]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.71]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:21<?, ?it/s, loss=1.7] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:36<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:44<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:48<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:49<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:52<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:56<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:00<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:02<?, ?it/s, loss=1.69]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.62]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, average loss: 1.6203705072402954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.67]\n",
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.67]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:01<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:04<?, ?it/s, loss=1.66]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, average loss: 1.6562522053718567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:06<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:07<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:09<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:12<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:15<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:17<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:18<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:20<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:22<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:25<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:27<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:40<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:47<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:01<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:08<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:14<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:21<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:28<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:35<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:42<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:48<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:54<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:59<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:05<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:10<?, ?it/s, loss=1.7] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, average loss: 1.695737361907959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [02:18<?, ?it/s, loss=1.69]\n",
      "Training:   0%|          | 0/30 [02:18<?, ?it/s, loss=1.69]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:03<?, ?it/s, loss=1.8]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:07<?, ?it/s, loss=1.69]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, average loss: 1.6851468086242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:10<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.59]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:19<?, ?it/s, loss=1.6] \u001b[A\n",
      "Training:   0%|          | 0/30 [00:24<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:29<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:33<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:38<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:42<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:46<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:50<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:54<?, ?it/s, loss=1.62]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:58<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:02<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:06<?, ?it/s, loss=1.61]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:10<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:13<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:17<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:24<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:32<?, ?it/s, loss=1.63]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:40<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:48<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:56<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:03<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:11<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:18<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:26<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:33<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:42<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:31<?, ?it/s, loss=1.55]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, average loss: 1.5478777885437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [07:25<?, ?it/s, loss=1.65]\n",
      "Training:   0%|          | 0/30 [07:25<?, ?it/s, loss=1.65]\n",
      "\n",
      "Training:   0%|          | 0/30 [00:14<?, ?it/s, loss=1.68]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:26<?, ?it/s, loss=1.52]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, average loss: 1.5236400961875916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:   0%|          | 0/30 [00:39<?, ?it/s, loss=1.55]\u001b[A\n",
      "Training:   0%|          | 0/30 [00:52<?, ?it/s, loss=1.58]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:05<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:19<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:29<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:40<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [01:51<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:01<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:11<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:21<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:31<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:41<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:49<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [02:56<?, ?it/s, loss=1.64]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:04<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:12<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:20<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:28<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:36<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:44<?, ?it/s, loss=1.65]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:51<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [03:59<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:07<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:15<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:22<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:30<?, ?it/s, loss=1.67]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:39<?, ?it/s, loss=1.66]\u001b[A\n",
      "Training:   0%|          | 0/30 [04:48<?, ?it/s, loss=1.67]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Epoch 10: 0.1960\n",
      "Tuning complete. Results saved to qa_multiple_choice_id_t5.json\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from openprompt.plms import T5TokenizerWrapper\n",
    "from datasets import load_from_disk\n",
    "from openprompt.pipeline_base import PromptDataLoader\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from openprompt.prompts import ManualTemplate, MixedTemplate\n",
    "from openprompt import PromptForClassification\n",
    "from openprompt.data_utils import FewShotSampler\n",
    "from random import shuffle\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from openprompt.prompts import ManualVerbalizer\n",
    "from openprompt.data_utils import InputExample\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "dataset_path = \"/lustre/work/client/users/minhos/cache/datasets/p3_cos_qa\"\n",
    "raw_dataset = load_from_disk(dataset_path)\n",
    "\n",
    "\n",
    "\n",
    "t5_path = \"/lustre/work/client/users/minhos/models_for_supercomputer/t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(t5_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_path)\n",
    "\n",
    "\n",
    "# Logging setup\n",
    "log_file = \"qa_multiple_choice_id_t5.json\"\n",
    "results = []\n",
    "\n",
    "label_map = {\"A\":0, \"B\":1, \"C\":2, \"D\":3 , \"E\":4}\n",
    "\n",
    "dataset = {}\n",
    "for split in ['train', 'validation']:\n",
    "    dataset[split] = []\n",
    "    if split == 'train':\n",
    "        raw_dataset[split] = raw_dataset[split].shuffle(seed=42).select(range(1000))\n",
    "    else:\n",
    "        raw_dataset[split] = raw_dataset[split].select(range(500))\n",
    "    \n",
    "    for idx, data in enumerate(raw_dataset[split]):\n",
    "        label_text = data[\"targets_pretokenized\"].strip()\n",
    "        label_numeric = label_map.get(label_text, -1)\n",
    "        input_example = InputExample(text_a=data['inputs_pretokenized'], guid=idx, label=label_numeric)\n",
    "        dataset[split].append(input_example)\n",
    "print(dataset['train'][0])\n",
    "print(type(dataset['train'][0]))\n",
    "\n",
    "\n",
    "sampler = FewShotSampler(num_examples_per_label=30)\n",
    "fewshot_data = sampler(dataset['train'], seed=42)\n",
    "def evaluate(prompt_model, dataloader):\n",
    "    prompt_model.eval()  # Set the model to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in dataloader:\n",
    "            logits = prompt_model(inputs)\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            labels = inputs['label']\n",
    "            \n",
    "            total += len(labels)\n",
    "            correct += (preds == labels).sum().item()\n",
    "        \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Hyperparameter search ranges\n",
    "learning_rates = [0.005, 0.001, 0.0005] # 0.0005, 0.001, 0.005\n",
    "warmup_steps = [10]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for warmup in warmup_steps:\n",
    "\n",
    "        model = T5ForConditionalGeneration.from_pretrained(t5_path)\n",
    "        tokenizer = T5Tokenizer.from_pretrained(t5_path)\n",
    "\n",
    "        template = ManualTemplate(\n",
    "            tokenizer=tokenizer,\n",
    "            text='{\"placeholder\":\"text_a\"} Which option is correct? {\"mask\"}',\n",
    "        )\n",
    "        verbalizer = ManualVerbalizer(\n",
    "            tokenizer=tokenizer,\n",
    "            num_classes=5,\n",
    "            label_words=[\n",
    "                [\"A\", \"a\", \"Option A\", \"first choice\"],\n",
    "                [\"B\", \"b\", \"Option B\", \"second choice\"],\n",
    "                [\"C\", \"c\", \"Option C\", \"third choice\"],\n",
    "                [\"D\", \"d\", \"Option D\", \"fourth choice\"],\n",
    "                [\"E\", \"e\", \"Option E\", \"fifth choice\"]\n",
    "            ]\n",
    "        )\n",
    "        wrapped_example = template.wrap_one_example(dataset['train'][0])\n",
    "        prompt_model = PromptForClassification(\n",
    "            plm=model,\n",
    "            template=template,\n",
    "            verbalizer=verbalizer,\n",
    "            freeze_plm=False,\n",
    "        )\n",
    "        train_dataloader = PromptDataLoader(\n",
    "            dataset = fewshot_data,\n",
    "            template=template,\n",
    "            tokenizer=tokenizer,\n",
    "            tokenizer_wrapper_class=T5TokenizerWrapper,\n",
    "            decoder_max_length=3, max_seq_length=480,\n",
    "            batch_size=5)\n",
    "\n",
    "\n",
    "        validation_dataloader = PromptDataLoader(\n",
    "            dataset = dataset[\"validation\"],\n",
    "            template=template,\n",
    "            tokenizer=tokenizer,\n",
    "            tokenizer_wrapper_class=T5TokenizerWrapper,\n",
    "            decoder_max_length=3, max_seq_length=480,\n",
    "            batch_size=20\n",
    "        )\n",
    "\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        # it's always good practice to set no decay to biase and LayerNorm parameters\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in prompt_model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in prompt_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        from tqdm import tqdm\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "        prompt_model.train()\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup, num_training_steps=1000)\n",
    "        for epoch in range(10):\n",
    "            total_loss = 0\n",
    "            pbar = tqdm(train_dataloader, desc=\"Training\")\n",
    "            for step, inputs in enumerate(train_dataloader):\n",
    "                logits = prompt_model(inputs)\n",
    "                labels = inputs['label']\n",
    "                loss = loss_func(logits, labels)\n",
    "                loss.backward()\n",
    "                total_loss += loss.item()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                pbar.set_postfix({\"loss\": total_loss / (step + 1)})\n",
    "                if step %100 ==1:\n",
    "                    print(\"Epoch {}, average loss: {}\".format(epoch+1, total_loss/(step+1)), flush=True)\n",
    "\n",
    "       \n",
    "    \n",
    "            # Validation after each epoch\n",
    "        val_accuracy = evaluate(prompt_model, validation_dataloader)\n",
    "        print(f\"Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.4f}\")\n",
    "        # Log results\n",
    "        result = {\n",
    "            \"learning_rate\": lr,\n",
    "            \"warmup_steps\": warmup,\n",
    "            \"final_loss\": total_loss / (10 * len(train_dataloader)),\n",
    "            \"accuracy\": val_accuracy\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # Save results to JSON\n",
    "        with open(log_file, \"w\") as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "            \n",
    "print(\"Tuning complete. Results saved to\", log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
